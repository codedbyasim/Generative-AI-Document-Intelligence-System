
## Generative AI Document Intelligence System

A complete end-to-end AI-powered system that extracts structured insights (like **Named Entities**, **Summaries**, **Key-Value pairs**) from **unstructured documents** such as PDFs and scanned images.

It combines the power of **OCR**, **NLP**, and **Large Language Models (LLMs)** to turn raw documents into actionable knowledge.

---

## Features

- Upload PDF or image documents
- Detect and extract both **digital** and **image-based** text
- Generate smart **summaries** using BART LLM
- ğŸ·Extract **Named Entities** (ORG, PERSON, LOCATION, etc.) using BERT NER
- Output text and summary files available for download
- Clean, easy-to-use **Flask web interface**

---

## System Architecture Overview

```bash
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Upload UI â”‚
                â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
               [Flask Backend]
                     â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                                 â”‚
[PDF/Image Input]              [Text Analysis]
     â”‚                                 â”‚
 OCR via Tesseract         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 (Image Text)              â”‚ Summarization â”‚  â† LLM (facebook/bart-large-cnn)
 +                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Digital Text via PyMuPDF â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 (PDF Text)               â”‚ Named Entitiesâ”‚  â† BERT NER (dslim/bert-base-NER)
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
````

---

## Project Structure

```
gen-ai-doc-intelligence/
â”‚
â”œâ”€â”€ app.py                         # Main Flask web server
â”œâ”€â”€ requirements.txt               # All dependencies
â”œâ”€â”€ README.md                      # Documentation
â”‚
â”œâ”€â”€ templates/                     # HTML Pages
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ upload.html
â”‚   â”œâ”€â”€ about.html
â”‚   â”œâ”€â”€ project_info.html
â”‚   â””â”€â”€ result.html
â”‚
â”œâ”€â”€ ai_engine/                     # Core AI modules
â”‚   â”œâ”€â”€ ocr_engine.py             # OCR using OpenCV + Tesseract
â”‚   â”œâ”€â”€ summarizer.py             # LLM summarisation (facebook/bart-large-cnn)
â”‚   â””â”€â”€ ner_extractor.py          # Named Entity Recognition (dslim/bert-base-NER)
â”‚
â”œâ”€â”€ pdf_processor/                 # PDF-specific handling
â”‚   â”œâ”€â”€ pdf_text_handler.py       # Extract both image-based and digital text
â”‚   â””â”€â”€ image_preprocessor.py     # Preprocess images to boost OCR quality
â”‚
â”œâ”€â”€ uploads/                      # Uploaded files
â””â”€â”€ outputs/                      # Extracted results
```

---

## Module Breakdown (Why & What)

### `app.py` â€“ Flask Web Application

* Acts as the **controller** to connect all modules.
* Routes:

  * `/`: Home page
  * `/upload`: Upload and process files
* Coordinates uploading, processing, and displaying results.

---

### `ocr_engine.py` â€“ Image Text Extraction

* Uses **Tesseract OCR + OpenCV**.
* Preprocessing improves accuracy for noisy or scanned images:

  * Grayscale conversion
  * Denoising
  * Adaptive Thresholding
  * Morphological operations
  * Upscaling low-res images
* Why? Many PDFs or uploads are images (not digital text).

---

### `pdf_text_handler.py` â€“ PDF Text Extraction (Hybrid)

* Uses **PyMuPDF (`fitz`)** to:

  * Extract **digital text** from PDFs
  * Convert **image-based pages** to PNGs for OCR
* Smart fallback: if digital text is short, use OCR instead.
* Why? Some PDFs contain only scanned images; others contain real selectable text.

---

### `image_preprocessor.py`

* Used for enhancing scanned documents before OCR.
* Applies:

  * Sharpening filters
  * Resize/denoise
* Helps clean up blurred or noisy documents for better results.

---

### `summarizer.py` â€“ Generate Summary

* Uses HuggingFaceâ€™s `facebook/bart-large-cnn` model.
* Accepts large raw text input and returns a summary.
* Why? To provide a **quick digest** of long documents.

---

### `ner_extractor.py` â€“ Named Entity Recognition

* Uses `dslim/bert-base-NER` model.
* Identifies:

  * Names (PERSON)
  * Organizations (ORG)
  * Locations (LOC), etc.
* Results include: `word`, `entity`, `confidence score`.
* Why? For semantic understanding and search.

---

## âš™Installation

### 1. Clone the repo

```bash
git clone https://github.com/codedbyasim/Generative-AI-Document-Intelligence-System.git
cd Generative-AI-Document-Intelligence-System
```

### 2. Install requirements

```bash
pip install -r requirements.txt
```

### 3. (Windows Only) Tesseract path

```python
# In ocr_engine.py
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
```

---

## Run Locally

```bash
python app.py
```

* Access at: [http://localhost:5000](http://localhost:5000)

---

## Sample Use Case

Upload a scanned letter â†’
System extracts text â†’
LLM summarizes it â†’
NER shows people/organizations â†’
Download output files.

---

## License

MIT â€“ Free to use, modify, and improve.

---

## ğŸ‘¤ Author

Built with â¤ï¸ by Asim Hanif
Feel free to connect and contribute!
